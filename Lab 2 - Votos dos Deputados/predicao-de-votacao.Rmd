---
title: "Predição de Votação de Deputados"
author: "Hugo Gabriel"
date: "11 de dezembro de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE)

library(caret)
library(tidyverse)
library(doMC)
```

```{r}
dados_votos <- read.csv("eleicoes2014.csv", encoding = "latin1")

dados_votos <- dados_votos %>%
  select(-c(nome, sequencial_candidato, numero_cadidato, cargo, setor_economico_receita, setor_economico_despesa))

for(i in 1:ncol(dados_votos)){
    dados_votos[is.na(dados_votos[,i]), i] <- mean(dados_votos[,i], na.rm = TRUE)
}
# dados_votos[is.na(dados_votos)] <- 0 # Testar com MEDIANA, MÉDIA, ...
```

```{r}
smp_size <- floor(.7*nrow(dados_votos))
set.seed(123)
train_id <- sample(seq_len(nrow(dados_votos)), size = smp_size)

treino <- dados_votos[train_id,]
teste <- dados_votos[-train_id,]

control <- trainControl(method = "repeatedcv", number = 5, repeats = 10, search = "random")
```

```{r}
library(parallel)
numCores <- detectCores()
registerDoMC(cores = numCores-1)
```

### Modelo de Regressão Ridge

```{r}
lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

model.ridge <- train(votos~., 
                     data = treino,
                     method = "ridge",
                     trControl = control,
                     preProcess = c('scale', 'center', 'nzv'),
                     metric = "RMSE",
                     tuneLength = 100)
model.ridge
```

### Modelo de Regressão Lasso

```{r}
model.lasso <- train(votos~., 
                     data = treino,
                     method = "lasso",
                     trControl = control,
                     preProcess = c('scale', 'center', 'nzv'),
                     metric = "RMSE",
                     tuneLength = 100)

model.lasso
```

### Modelo de Regressão KNN

```{r}
model.knn <- train(votos~., 
                     data = treino,
                     method = "knn",
                     trControl = control,
                     preProcess = c('scale', 'center', 'nzv'),
                     metric = "RMSE",
                     tuneLength = 100)

model.knn
```

## Comparando os modelos gerados

```{r}
value <- c(min(model.lasso$results["RMSE"], na.rm = TRUE),
           min(model.ridge$results["RMSE"], na.rm = TRUE),
           min(model.knn$results["RMSE"], na.rm = TRUE))
label <- c("Lasso", "Ridge", "KNN")

data <- data.frame(label, value)

plot(data)
```
Observa-se que a regressão Lasso apresentou o menor erro dentre as analisadas

## Quais as variáveis mais importantes?

Os gráficos abaixo apresentam a importància de cada variável em seus respectivos modelos.
### Ridge
```{r}
ggplot(varImp(model.ridge))
```

### Lasso
```{r}
ggplot(varImp(model.lasso))
```

O gráfico mostra que a algumas variáveis apresentam pouca importância para o modelo, como por exemplo, UF (que foi a variável descartada pela regressão Lasso).

## Melhor modelo sem validação cruzada

Observaremos agora o resultado do modelo de regressão Lasso sem o uso de validação cruzada, deste modo, usaremos o método de validação padrão da função train.
```{r}
model.lasso_2 <- train(votos~., 
                     data = treino,
                     method = "lasso",
                     preProcess = c('scale', 'center', 'nzv'),
                     metric = "RMSE",
                     tuneLength = 100)
model.lasso_2
```

